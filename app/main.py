import os
import time
import requests
import google.generativeai as genai
import json
import logging
from datetime import datetime, timedelta, timezone, MINYEAR
from dotenv import load_dotenv
import re
from kubernetes import client, config, watch
from kubernetes.client.exceptions import ApiException


# --- T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env (cho ph√°t tri·ªÉn c·ª•c b·ªô) ---
load_dotenv()

# --- C·∫•u h√¨nh Logging ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- T·∫£i c·∫•u h√¨nh t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ---
LOKI_URL = os.environ.get("LOKI_URL", "http://loki-read.monitoring.svc.cluster.local:3100")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
QUERY_INTERVAL_SECONDS = int(os.environ.get("QUERY_INTERVAL_SECONDS", 60))
LOKI_QUERY_RANGE_MINUTES = int(os.environ.get("LOKI_QUERY_RANGE_MINUTES", 5))
LOKI_QUERY_LIMIT = int(os.environ.get("LOKI_QUERY_LIMIT", 1000))
K8S_NAMESPACES_STR = os.environ.get("K8S_NAMESPACES", "kube-system")
K8S_NAMESPACES = [ns.strip() for ns in K8S_NAMESPACES_STR.split(',') if ns.strip()]
MIN_LOG_LEVEL_FOR_GEMINI = os.environ.get("MIN_LOG_LEVEL_FOR_GEMINI", "INFO")
GEMINI_MODEL_NAME = os.environ.get("GEMINI_MODEL_NAME", "gemini-1.5-flash")
ALERT_SEVERITY_LEVELS_STR = os.environ.get("ALERT_SEVERITY_LEVELS", "ERROR,CRITICAL")
ALERT_SEVERITY_LEVELS = [level.strip().upper() for level in ALERT_SEVERITY_LEVELS_STR.split(',') if level.strip()]

# --- C·∫•u h√¨nh Kubernetes Client ---
try:
    config.load_incluster_config()
    logging.info("Loaded in-cluster Kubernetes config.")
except config.ConfigException:
    try:
        config.load_kube_config()
        logging.info("Loaded local Kubernetes config (kubeconfig).")
    except config.ConfigException:
        logging.error("Could not configure Kubernetes client. Exiting.")
        exit(1)

k8s_core_v1 = client.CoreV1Api()
k8s_apps_v1 = client.AppsV1Api()

# C·∫•u h√¨nh Gemini Client
if not GEMINI_API_KEY:
    logging.error("GEMINI_API_KEY is not set! Ensure it's in your .env file or environment variables.")
    exit(1)
genai.configure(api_key=GEMINI_API_KEY)
gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)

# --- H√†m Query Loki ---
# (Gi·ªØ nguy√™n)
def query_loki(start_time, end_time):
    loki_api_endpoint = f"{LOKI_URL}/loki/api/v1/query_range"
    if not K8S_NAMESPACES: logging.error("No namespaces configured in K8S_NAMESPACES. Exiting."); return None
    namespace_regex = "|".join(K8S_NAMESPACES)
    logql_query = f'{{namespace=~"{namespace_regex}"}}'
    params = {'query': logql_query, 'start': int(start_time.timestamp() * 1e9), 'end': int(end_time.timestamp() * 1e9), 'limit': LOKI_QUERY_LIMIT, 'direction': 'forward'}
    logging.info(f"Querying Loki: {logql_query} from {start_time} to {end_time}")
    try:
        headers = {'Accept': 'application/json'}
        response = requests.get(loki_api_endpoint, params=params, headers=headers, timeout=30); response.raise_for_status(); data = response.json()
        if 'data' in data and 'result' in data['data']:
            log_entries = []
            for stream in data['data']['result']:
                for timestamp_ns, log_line in stream['values']: log_entries.append({"timestamp": datetime.fromtimestamp(int(timestamp_ns) / 1e9, tz=timezone.utc), "message": log_line.strip(), "labels": stream.get('stream', {})})
            log_entries.sort(key=lambda x: x['timestamp']); logging.info(f"Received {len(log_entries)} log entries from Loki for namespaces: {K8S_NAMESPACES_STR}"); return log_entries
        else: logging.warning(f"No 'result' data found in Loki response (Status: {response.status_code}). Response: {response.text[:500]}"); return []
    except requests.exceptions.RequestException as e: error_message = f"Error querying Loki API: {e}"; logging.error(error_message); return []
    except json.JSONDecodeError as e: logging.error(f"Error decoding Loki JSON response: {e} - Response text: {response.text[:500]}"); return []
    except Exception as e: logging.error(f"An unexpected error occurred during Loki query: {e}", exc_info=True); return []


# --- H√†m ti·ªÅn x·ª≠ l√Ω v√† l·ªçc log ---
# (Gi·ªØ nguy√™n)
def preprocess_and_filter(log_entries):
    filtered_logs = []
    log_levels = ["DEBUG", "INFO", "NOTICE", "WARNING", "ERROR", "CRITICAL", "ALERT", "EMERGENCY"]
    min_level_index = -1
    try: min_level_index = log_levels.index(MIN_LOG_LEVEL_FOR_GEMINI.upper())
    except ValueError: logging.warning(f"Invalid MIN_LOG_LEVEL_FOR_GEMINI: {MIN_LOG_LEVEL_FOR_GEMINI}. Defaulting to INFO."); min_level_index = log_levels.index("INFO")
    keywords_indicating_problem = ["FAIL", "ERROR", "CRASH", "EXCEPTION", "UNAVAILABLE", "FATAL", "PANIC"]
    for entry in log_entries:
        log_line = entry['message']; log_line_upper = log_line.upper(); level_detected = False
        for i, level in enumerate(log_levels):
            if f" {level} " in f" {log_line_upper} " or log_line_upper.startswith(level+":") or f"[{level}]" in log_line_upper or f"level={level.lower()}" in log_line_upper or f"\"level\":\"{level.lower()}\"" in log_line_upper:
                if i >= min_level_index: filtered_logs.append(entry); level_detected = True; break
        if not level_detected:
            if any(keyword in log_line_upper for keyword in keywords_indicating_problem):
                    warning_index = log_levels.index("WARNING")
                    if min_level_index <= warning_index: filtered_logs.append(entry)
    logging.info(f"Filtered {len(log_entries)} logs down to {len(filtered_logs)} for potential Gemini analysis (Min Level: {MIN_LOG_LEVEL_FOR_GEMINI}).")
    return filtered_logs

# --- C√°c h√†m l·∫•y th√¥ng tin Kubernetes ---
# (Gi·ªØ nguy√™n: get_pod_info, get_node_info, get_pod_events, format_k8s_context)
def get_pod_info(namespace, pod_name):
    try:
        pod = k8s_core_v1.read_namespaced_pod(name=pod_name, namespace=namespace)
        info = {"name": pod.metadata.name,"namespace": pod.metadata.namespace,"status": pod.status.phase,"node_name": pod.spec.node_name,"start_time": pod.status.start_time.isoformat() if pod.status.start_time else "N/A","restarts": sum(cs.restart_count for cs in pod.status.container_statuses) if pod.status.container_statuses else 0,"conditions": {cond.type: {"status": cond.status, "reason": cond.reason, "message": cond.message} for cond in pod.status.conditions} if pod.status.conditions else {},"container_statuses": {}}
        if pod.status.container_statuses:
            for cs in pod.status.container_statuses:
                state_info = "N/A";
                if cs.state:
                    if cs.state.running: state_info = "Running"
                    elif cs.state.waiting: state_info = f"Waiting ({cs.state.waiting.reason})"
                    elif cs.state.terminated: state_info = f"Terminated ({cs.state.terminated.reason}, ExitCode: {cs.state.terminated.exit_code})"
                info["container_statuses"][cs.name] = {"ready": cs.ready,"restart_count": cs.restart_count,"state": state_info}
        return info
    except ApiException as e: logging.warning(f"Could not get pod info for {namespace}/{pod_name}: {e.status} {e.reason}"); return None
    except Exception as e: logging.error(f"Unexpected error getting pod info for {namespace}/{pod_name}: {e}", exc_info=True); return None

def get_node_info(node_name):
    if not node_name: return None
    try:
        node = k8s_core_v1.read_node(name=node_name)
        conditions = {cond.type: {"status": cond.status, "reason": cond.reason, "message": cond.message} for cond in node.status.conditions} if node.status.conditions else {}
        info = {"name": node.metadata.name,"conditions": conditions,"allocatable_cpu": node.status.allocatable.get('cpu', 'N/A'),"allocatable_memory": node.status.allocatable.get('memory', 'N/A'),"kubelet_version": node.status.node_info.kubelet_version}
        return info
    except ApiException as e: logging.warning(f"Could not get node info for {node_name}: {e.status} {e.reason}"); return None
    except Exception as e: logging.error(f"Unexpected error getting node info for {node_name}: {e}", exc_info=True); return None

def get_pod_events(namespace, pod_name, since_minutes=15):
    try:
        since_time = datetime.now(timezone.utc) - timedelta(minutes=since_minutes)
        field_selector = f"involvedObject.kind=Pod,involvedObject.name={pod_name},involvedObject.namespace={namespace}"
        events = k8s_core_v1.list_namespaced_event(namespace=namespace, field_selector=field_selector, limit=10)
        recent_events = []
        if events and events.items:
                sorted_events = sorted(events.items, key=lambda e: e.last_timestamp or e.metadata.creation_timestamp or datetime(MINYEAR, 1, 1, tzinfo=timezone.utc), reverse=True)
                for event in sorted_events:
                    event_time = event.last_timestamp or event.metadata.creation_timestamp
                    if event_time and event_time >= since_time: recent_events.append({"time": event_time.isoformat(),"type": event.type,"reason": event.reason,"message": event.message,"count": event.count})
                    if len(recent_events) >= 10 or (event_time and event_time < since_time): break
        return recent_events
    except ApiException as e:
        if e.status != 403: logging.warning(f"Could not list events for pod {namespace}/{pod_name}: {e.status} {e.reason}")
        return []
    except Exception as e: logging.error(f"Unexpected error listing events for pod {namespace}/{pod_name}: {e}", exc_info=True); return []

def format_k8s_context(pod_info, node_info, pod_events):
    context_str = "\n--- Ng·ªØ c·∫£nh Kubernetes ---\n"
    if pod_info:
        context_str += f"Pod: {pod_info['namespace']}/{pod_info['name']}\n"
        context_str += f"  Tr·∫°ng th√°i: {pod_info['status']}\n"
        context_str += f"  Node: {pod_info['node_name']}\n"
        context_str += f"  S·ªë l·∫ßn kh·ªüi ƒë·ªông l·∫°i: {pod_info['restarts']}\n"
        if pod_info.get('container_statuses'):
                context_str += "  Tr·∫°ng th√°i Container:\n"
                for name, status in pod_info['container_statuses'].items(): context_str += f"    - {name}: {status['state']} (Ready: {status['ready']}, Restarts: {status['restart_count']})\n"
        if pod_info.get('conditions'):
                problematic_conditions = [f"{ctype}({cinfo['status']}-{cinfo.get('reason','N/A')})" for ctype, cinfo in pod_info['conditions'].items() if cinfo.get('status') != 'True']
                if problematic_conditions: context_str += f"  ƒêi·ªÅu ki·ªán Pod b·∫•t th∆∞·ªùng: {', '.join(problematic_conditions)}\n"
    if node_info:
        context_str += f"Node: {node_info['name']}\n"
        if node_info.get('conditions'):
                problematic_conditions = [f"{ctype}({cinfo['status']}-{cinfo.get('reason','N/A')})" for ctype, cinfo in node_info['conditions'].items() if cinfo.get('status') != ('True' if ctype == 'Ready' else 'False')]
                if problematic_conditions: context_str += f"  ƒêi·ªÅu ki·ªán Node b·∫•t th∆∞·ªùng: {', '.join(problematic_conditions)}\n"
    if pod_events:
        context_str += "S·ª± ki·ªán Pod g·∫ßn ƒë√¢y (t·ªëi ƒëa 10):\n"
        for event in pod_events: context_str += f"  - [{event['time']}] {event['type']} {event['reason']} (x{event.get('count',1)}): {event['message'][:150]}\n"
    context_str += "--- K·∫øt th√∫c ng·ªØ c·∫£nh ---\n"; return context_str


# --- H√†m t∆∞∆°ng t√°c v·ªõi Gemini ---
def analyze_with_gemini(log_batch, k8s_context=""):
    """
    G·ª≠i m·ªôt l√¥ log v√† ng·ªØ c·∫£nh K8s ƒë·∫øn Gemini ƒë·ªÉ ph√¢n t√≠ch.
    C·ªë g·∫Øng x·ª≠ l√Ω JSON b·ªã l·ªói nh·∫π.
    """
    if not log_batch: return None
    first_log_namespace = log_batch[0].get('labels', {}).get('namespace', 'unknown')
    log_text = "\n".join([f"[{entry['timestamp'].isoformat()}] {entry.get('labels', {}).get('pod', 'unknown_pod')}: {entry['message']}" for entry in log_batch])
    prompt = f"""
    Ph√¢n t√≠ch c√°c d√≤ng log Kubernetes sau ƒë√¢y t·ª´ namespace '{first_log_namespace}'.
    H√£y xem x√©t **ng·ªØ c·∫£nh Kubernetes** ƒë∆∞·ª£c cung c·∫•p d∆∞·ªõi ƒë√¢y ƒë·ªÉ ƒë∆∞a ra ph√¢n t√≠ch ch√≠nh x√°c h∆°n.
    X√°c ƒë·ªãnh m·ª©c ƒë·ªô nghi√™m tr·ªçng t·ªïng th·ªÉ cho l√¥ log n√†y (ch·ªçn m·ªôt: INFO, WARNING, ERROR, CRITICAL).
    N·∫øu m·ª©c ƒë·ªô nghi√™m tr·ªçng l√† ERROR ho·∫∑c CRITICAL, h√£y cung c·∫•p m·ªôt b·∫£n t√≥m t·∫Øt ng·∫Øn g·ªçn (1-2 c√¢u) b·∫±ng **ti·∫øng Vi·ªát** gi·∫£i th√≠ch v·∫•n ƒë·ªÅ c·ªët l√µi ƒë∆∞·ª£c ph√°t hi·ªán, k·∫øt h·ª£p th√¥ng tin t·ª´ log v√† ng·ªØ c·∫£nh.
    T·∫≠p trung v√†o c√°c t√°c ƒë·ªông ti·ªÅm ·∫©n ƒë·∫øn s·ª± ·ªïn ƒë·ªãnh c·ªßa cluster ho·∫∑c t√≠nh kh·∫£ d·ª•ng c·ªßa ·ª©ng d·ª•ng. N·∫øu m·ª©c ƒë·ªô nghi√™m tr·ªçng l√† INFO ho·∫∑c WARNING, b·∫£n t√≥m t·∫Øt c√≥ th·ªÉ ng·∫Øn g·ªçn ho·∫∑c null.
    C√°c d√≤ng log:
    --- START LOGS ---
    {log_text[:25000]}
    --- END LOGS ---
    {k8s_context[:5000]}
    Ch·ªâ tr·∫£ l·ªùi b·∫±ng ƒë·ªãnh d·∫°ng JSON v·ªõi c√°c kh√≥a "severity" v√† "summary". V√≠ d·ª•: {{"severity": "CRITICAL", "summary": "Pod 'coredns-xyz' trong namespace 'kube-system' li√™n t·ª•c kh·ªüi ƒë·ªông l·∫°i (restart count cao) v√† log b√°o l·ªói k·∫øt n·ªëi upstream. Ki·ªÉm tra c·∫•u h√¨nh CoreDNS v√† k·∫øt n·ªëi m·∫°ng c·ªßa node."}}
    """
    logging.info(f"Sending {len(log_batch)} logs ({len(log_text)} chars) and context ({len(k8s_context)} chars) from namespace '{first_log_namespace}' to Gemini for analysis...")
    try:
        # --- B·∫ÆT ƒê·∫¶U THAY ƒê·ªîI: Gi·ªõi h·∫°n max_output_tokens ---
        response = gemini_model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=250 # Gi·ªõi h·∫°n s·ªë token tr·∫£ v·ªÅ ƒë·ªÉ tr√°nh b·ªã c·∫Øt ngang
            ),
            request_options={'timeout': 90}
        )
        # --- K·∫æT TH√öC THAY ƒê·ªîI ---

        if not response.parts:
                logging.warning("Gemini response has no parts.");
                if hasattr(response, 'prompt_feedback') and response.prompt_feedback: logging.warning(f"Gemini prompt feedback: {response.prompt_feedback}")
                return None

        response_text = response.text.strip()
        # --- B·∫ÆT ƒê·∫¶U THAY ƒê·ªîI: Log to√†n b·ªô response th√¥ khi c√≥ l·ªói parse ---
        logging.info(f"Received response from Gemini (raw): {response_text}") # Log tr∆∞·ªõc khi parse

        # C·ªë g·∫Øng d·ªçn d·∫πp response tr∆∞·ªõc khi parse
        cleaned_response_text = response_text
        if cleaned_response_text.startswith("```json"):
            cleaned_response_text = cleaned_response_text.strip("```json").strip("`").strip()
        elif cleaned_response_text.startswith("```"):
                cleaned_response_text = cleaned_response_text.strip("```").strip()
        # Th·ª≠ t√¨m JSON h·ª£p l·ªá ƒë·∫ßu ti√™n trong chu·ªói (ph√≤ng tr∆∞·ªùng h·ª£p c√≥ text th·ª´a)
        match = re.search(r'\{.*\}', cleaned_response_text, re.DOTALL)
        if match:
            json_string_to_parse = match.group(0)
        else:
            json_string_to_parse = cleaned_response_text # D√πng b·∫£n g·ªëc n·∫øu kh√¥ng t√¨m th·∫•y {}

        try:
            analysis_result = json.loads(json_string_to_parse)
            if "severity" in analysis_result:
                logging.info(f"Successfully parsed Gemini JSON: {analysis_result}")
                return analysis_result
            else:
                logging.warning(f"Gemini response JSON missing 'severity' key. Raw response: {response_text}")
                severity = "WARNING"; summary_vi = "Kh√¥ng th·ªÉ ph√¢n t√≠ch JSON t·ª´ Gemini (thi·∫øu key 'severity'). Ph·∫£n h·ªìi th√¥: " + response_text[:200]
                if "CRITICAL" in response_text.upper(): severity = "CRITICAL"
                elif "ERROR" in response_text.upper(): severity = "ERROR"
                return {"severity": severity, "summary": summary_vi}

        except json.JSONDecodeError as json_err:
            # Log l·ªói c·ª• th·ªÉ v√† to√†n b·ªô response th√¥
            logging.warning(f"Failed to decode Gemini response as JSON: {json_err}. Raw response: {response_text}")
            severity = "WARNING"; summary_vi = f"Ph·∫£n h·ªìi Gemini kh√¥ng ph·∫£i JSON h·ª£p l·ªá ({json_err}): " + response_text[:200]
            if "CRITICAL" in response_text.upper(): severity = "CRITICAL"
            elif "ERROR" in response_text.upper(): severity = "ERROR"
            return {"severity": severity, "summary": summary_vi}
        # --- K·∫æT TH√öC THAY ƒê·ªîI ---

    except Exception as e: logging.error(f"Error calling Gemini API: {e}", exc_info=True); return None

# --- H√†m g·ª≠i c·∫£nh b√°o Telegram ---
# (Gi·ªØ nguy√™n)
def send_telegram_alert(message):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID: logging.warning("Telegram Bot Token or Chat ID is not configured. Skipping alert."); return
    telegram_api_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    max_len = 4096; truncated_message = message[:max_len-50] + "..." if len(message) > max_len else message
    payload = {'chat_id': TELEGRAM_CHAT_ID, 'text': truncated_message, 'parse_mode': 'Markdown'}
    try:
        response = requests.post(telegram_api_url, json=payload, timeout=10); response.raise_for_status()
        logging.info(f"Sent alert to Telegram. Response: {response.json()}")
    except requests.exceptions.RequestException as e:
        logging.error(f"Error sending Telegram alert: {e}")
        if e.response is not None: logging.error(f"Telegram API Response Status: {e.response.status_code}\nTelegram API Response Body: {e.response.text}")
    except Exception as e: logging.error(f"An unexpected error occurred during Telegram send: {e}", exc_info=True)

# --- V√≤ng l·∫∑p ch√≠nh c·ªßa Agent ---
# (Gi·ªØ nguy√™n)
def main_loop():
    last_query_time = datetime.now(timezone.utc) - timedelta(minutes=LOKI_QUERY_RANGE_MINUTES)
    while True:
        current_time = datetime.now(timezone.utc); start_query = last_query_time + timedelta(seconds=1); end_query = current_time
        if start_query >= end_query: logging.info(f"Start time {start_query} is after or equal to end time {end_query}. Skipping query cycle."); last_query_time = end_query; time.sleep(QUERY_INTERVAL_SECONDS); continue
        log_entries = query_loki(start_query, end_query)
        if log_entries is None: logging.error("Configuration error detected in query_loki. Stopping agent."); break
        if log_entries:
            logs_to_analyze = preprocess_and_filter(log_entries)
            if logs_to_analyze:
                logs_by_pod = {}
                for log in logs_to_analyze:
                    labels = log.get('labels', {}); ns = labels.get('namespace', 'unknown_namespace'); pod = labels.get('pod', 'unknown_pod')
                    if ns == 'unknown_namespace' or pod == 'unknown_pod': continue
                    pod_key = f"{ns}/{pod}";
                    if pod_key not in logs_by_pod: logs_by_pod[pod_key] = []
                    logs_by_pod[pod_key].append(log)
                for pod_key, pod_logs in logs_by_pod.items():
                    namespace, pod_name = pod_key.split('/', 1); logging.info(f"Processing {len(pod_logs)} logs for pod '{pod_key}'")
                    pod_info = get_pod_info(namespace, pod_name); node_info = None; pod_events = []
                    if pod_info: node_info = get_node_info(pod_info.get('node_name')); pod_events = get_pod_events(namespace, pod_name)
                    k8s_context_str = format_k8s_context(pod_info, node_info, pod_events)
                    batch_size = 30
                    for i in range(0, len(pod_logs), batch_size):
                        batch = pod_logs[i:i+batch_size]; analysis_result = analyze_with_gemini(batch, k8s_context_str)
                        if analysis_result:
                            severity = analysis_result.get("severity", "UNKNOWN").upper(); summary = analysis_result.get("summary", "N/A")
                            logging.info(f"Gemini analysis result for '{pod_key}': Severity={severity}, Summary={summary}")
                            if severity in ALERT_SEVERITY_LEVELS:
                                sample_logs = "\n".join([f"- `{log['message'][:150]}`" for log in batch[:3]])
                                alert_message = f"""üö® *C·∫£nh b√°o Log K8s (Pod: {pod_key})* üö®\n*M·ª©c ƒë·ªô:* `{severity}`\n*T√≥m t·∫Øt:* {summary}\n*Kho·∫£ng th·ªùi gian log:* `{start_query.strftime('%Y-%m-%d %H:%M:%S')}` - `{end_query.strftime('%Y-%m-%d %H:%M:%S')}` UTC\n*Log m·∫´u:*\n{sample_logs}\n\n_Vui l√≤ng ki·ªÉm tra log v√† tr·∫°ng th√°i pod/node/events tr√™n K8s ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt._"""
                                send_telegram_alert(alert_message)
                        else: logging.warning(f"Gemini analysis failed or returned no result for a batch in pod '{pod_key}'.")
                        time.sleep(3)
        last_query_time = end_query
        elapsed_time = (datetime.now(timezone.utc) - current_time).total_seconds()
        sleep_time = max(0, QUERY_INTERVAL_SECONDS - elapsed_time)
        logging.info(f"Cycle finished in {elapsed_time:.2f}s. Sleeping for {sleep_time:.2f} seconds...")
        time.sleep(sleep_time)

if __name__ == "__main__":
    logging.info(f"Starting Kubernetes Log Monitoring Agent for namespaces: {K8S_NAMESPACES_STR}")
    logging.info(f"Minimum log level for Gemini analysis: {MIN_LOG_LEVEL_FOR_GEMINI}")
    logging.info(f"Alerting for severity levels: {ALERT_SEVERITY_LEVELS_STR}")
    if not K8S_NAMESPACES: logging.error("K8S_NAMESPACES environment variable is not set or is empty. Exiting."); exit(1)
    if not all([LOKI_URL, GEMINI_API_KEY, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID]): logging.error("One or more required environment variables are missing. Ensure they are set. Exiting."); exit(1)
    try: main_loop()
    except KeyboardInterrupt: logging.info("Agent stopped by user.")
    except Exception as e: logging.error(f"Unhandled exception in main loop: {e}", exc_info=True)

